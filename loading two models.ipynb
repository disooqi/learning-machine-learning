{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_model = '/home/disooqi/qmdis-post-processor-full/arabic_dialect_identification/lexical/model'\n",
    "acoustic_model = '/home/disooqi/qmdis-post-processor-full/arabic_dialect_identification/acoustic/model'\n",
    "\n",
    "suwan_model = os.path.join(lexical_model, 'model60400.ckpt')\n",
    "model_path = os.path.join(acoustic_model, 'model910000.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class siamese:\n",
    "\n",
    "    # Create model\n",
    "    def __init__(self,input_dim):\n",
    "        self.x1 = tf.placeholder(tf.float32, [None, input_dim])\n",
    "        self.x2 = tf.placeholder(tf.float32, [None, input_dim])\n",
    "\n",
    "        with tf.variable_scope(\"siamese\") as scope:\n",
    "            self.a1,self.b1,self.o1 = self.network(self.x1)\n",
    "            scope.reuse_variables()\n",
    "            self.a1,self.b2,self.o2 = self.network(self.x2)\n",
    "            \n",
    "        # Create loss\n",
    "        self.y_ = tf.placeholder(tf.float32, [None])\n",
    "        self.loss = self.loss_with_cds()\n",
    "\n",
    "    def network(self, x):\n",
    "        weights = []\n",
    "        kernel_size =150\n",
    "        stride = 18\n",
    "        depth=40\n",
    "        conv1 = self.conv_layer(x, kernel_size,stride,depth,'conv1')\n",
    "        conv1r = tf.nn.relu(conv1)\n",
    "        n_prev_weight = int(x.get_shape()[1])\n",
    "        conv1_d = tf.reshape(conv1r,[-1, int(round(n_prev_weight/stride+0.5)*depth)])\n",
    "        \n",
    "        fc1 = self.fc_layer(conv1_d, 1500, \"fc1\")\n",
    "        ac1 = tf.nn.relu(fc1)\n",
    "        fc2 = self.fc_layer(ac1, 600, \"fc2\")   \n",
    "        ac2 = tf.nn.relu(fc2)\n",
    "        fc3 = self.fc_layer(ac2, 200, \"fc3\")\n",
    "        return fc1,fc2,fc3\n",
    "\n",
    "    def fc_layer(self, bottom, n_weight, name):\n",
    "        # print( bottom.get_shape())\n",
    "        n_prev_weight = bottom.get_shape()[1]\n",
    "        W = tf.get_variable(name+'W', dtype=tf.float32, shape=[n_prev_weight, n_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable(name+'b', dtype=tf.float32, initializer=tf.random_uniform([n_weight],-0.001,0.001, dtype=tf.float32))\n",
    "        fc = tf.nn.bias_add(tf.matmul(bottom, W), b)\n",
    "        return fc\n",
    "\n",
    "    def conv_layer(self, bottom, kernel_size, stride, depth, name):        \n",
    "        n_prev_weight = int(bottom.get_shape()[1])\n",
    "        num_channels = 1 # for 1 dimension\n",
    "        inputlayer = tf.reshape(bottom, [-1,n_prev_weight,1])\n",
    "        initer = tf.truncated_normal_initializer(stddev=0.1)\n",
    "        W = tf.get_variable(name+'W', dtype=tf.float32, shape=[kernel_size, num_channels, depth], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable(name+'b', dtype=tf.float32, initializer=tf.constant(0.001, shape=[depth*num_channels], dtype=tf.float32))\n",
    "        \n",
    "        conv = tf.nn.bias_add( tf.nn.conv1d(inputlayer, W, stride, padding='SAME'), b)\n",
    "        return conv\n",
    "\n",
    "    def loss_with_cds(self):\n",
    "        labels_t = self.y_\n",
    "        cds = tf.reduce_sum(tf.multiply(self.o1,self.o2),1)\n",
    "        eucd2 = tf.reduce_mean(tf.pow(tf.subtract(labels_t,cds),2))\n",
    "        eucd = tf.sqrt(eucd2, name=\"eucd\")\n",
    "        return eucd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/disooqi/qmdis-post-processor-full/arabic_dialect_identification/lexical/model/model60400.ckpt\n"
     ]
    }
   ],
   "source": [
    "graph_1 = tf.Graph()\n",
    "\n",
    "with graph_1.as_default():\n",
    "    input_dim = 41657\n",
    "    siamese = siamese(input_dim)\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    learning_rate = tf.train.exponential_decay(0.01, global_step, 5000, 0.99, staircase=True)\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(siamese.loss, global_step=global_step)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver.restore(sess, suwan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None,None,40])\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "s = tf.placeholder(tf.int32, [None,2])\n",
    "\n",
    "softmax_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn:\n",
    "    # Create model\n",
    "    def __init__(self, x1, y_, y_string, shapes_batch, softmax_num):\n",
    "        self.ea, self.eb, self.o1,self.res1,self.conv,self.ac1,self.ac2 = self.net(x1, shapes_batch, softmax_num)\n",
    "            \n",
    "        # Create loss\n",
    "        self.loss    = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_, logits=self.o1))\n",
    "        self.label=y_\n",
    "        self.shape = shapes_batch\n",
    "        self.true_length = x1\n",
    "        self.label_string=y_string\n",
    "\n",
    "    def net(self,x, shapes_batch,softmax_num):   \n",
    "        \n",
    "        shape_list = shapes_batch[:,0]\n",
    "\n",
    "        featdim = 40 #channel\n",
    "        weights = []\n",
    "        kernel_size =5\n",
    "        stride = 1\n",
    "        depth = 500\n",
    "                \n",
    "        shape_list = shape_list/stride\n",
    "        conv1 = self.conv_layer(x,kernel_size,featdim,stride,depth,'conv1',shape_list)\n",
    "        conv1r= tf.nn.relu(conv1)\n",
    "       \n",
    "\n",
    "        featdim = depth #channel\n",
    "        weights = []\n",
    "        kernel_size =7\n",
    "        stride = 2\n",
    "        depth = 500\n",
    "                \n",
    "        shape_list = shape_list/stride\n",
    "        conv2 = self.conv_layer(conv1r,kernel_size,featdim,stride,depth,'conv2',shape_list)\n",
    "        conv2r= tf.nn.relu(conv2)\n",
    "       \n",
    "        featdim = depth #channel\n",
    "        weights = []\n",
    "        kernel_size =1\n",
    "        stride = 1\n",
    "        depth = 500\n",
    "                \n",
    "        shape_list = shape_list/stride\n",
    "        conv3 = self.conv_layer(conv2r,kernel_size,featdim,stride,depth,'conv3',shape_list)\n",
    "        conv3r= tf.nn.relu(conv3)\n",
    "       \n",
    "        featdim = depth #channel\n",
    "        weights = []\n",
    "        kernel_size =1\n",
    "        stride = 1\n",
    "        depth = 3000\n",
    "                \n",
    "        shape_list = shape_list/stride\n",
    "        conv4 = self.conv_layer(conv3r,kernel_size,featdim,stride,depth,'conv4',shape_list)\n",
    "        conv4r= tf.nn.relu(conv4)\n",
    "        \n",
    "        print ('Hi I am conv1', conv1)\n",
    "        \n",
    "        shape_list = tf.cast(shape_list, tf.float32)\n",
    "        shape_list = tf.reshape(shape_list,[-1,1,1])\n",
    "        mean = tf.reduce_sum(conv4r,1,keep_dims=True)/shape_list\n",
    "        res1=tf.squeeze(mean,axis=1)\n",
    "        \n",
    "\n",
    "        fc1 = self.fc_layer(res1,1500,\"fc1\")\n",
    "        ac1 = tf.nn.relu(fc1)\n",
    "        fc2 = self.fc_layer(ac1,600,\"fc2\")\n",
    "        ac2 = tf.nn.relu(fc2)\n",
    "        \n",
    "        fc3 = self.fc_layer(ac2,softmax_num,\"fc3\")\n",
    "        return fc1, fc2, fc3,res1,conv1r,ac1,ac2\n",
    "        \n",
    "    def xavier_init(self,n_inputs, n_outputs, uniform=True):\n",
    "        if uniform:\n",
    "            init_range = np.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "            return tf.random_uniform_initializer(-init_range, init_range)\n",
    "        else:\n",
    "            stddev = np.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "            return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "    def fc_layer(self, bottom, n_weight, name):\n",
    "        print(bottom.get_shape())\n",
    "        assert len(bottom.get_shape()) == 2\n",
    "        n_prev_weight = bottom.get_shape()[1]\n",
    "\n",
    "        initer = self.xavier_init(int(n_prev_weight),n_weight)\n",
    "        W = tf.get_variable(name+'W', dtype=tf.float32, shape=[n_prev_weight, n_weight], initializer=initer)\n",
    "        b = tf.get_variable(name+'b', dtype=tf.float32, initializer=tf.random_uniform([n_weight],-0.001,0.001, dtype=tf.float32))\n",
    "        fc = tf.nn.bias_add(tf.matmul(bottom, W), b)\n",
    "        return fc\n",
    "    \n",
    "    \n",
    "    def conv_layer(self, bottom, kernel_size,num_channels, stride, depth, name, shape_list):   # n_prev_weight = int(bottom.get_shape()[1])\n",
    "        n_prev_weight = tf.shape(bottom)[1]\n",
    "\n",
    "        inputlayer=bottom\n",
    "        initer = tf.truncated_normal_initializer(stddev=0.1)\n",
    "\n",
    "        W = tf.get_variable(name+'W', dtype=tf.float32, shape=[kernel_size, num_channels, depth], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable(name+'b', dtype=tf.float32, initializer=tf.constant(0.001, shape=[depth], dtype=tf.float32))\n",
    "\n",
    "        conv =  ( tf.nn.bias_add( tf.nn.conv1d(inputlayer, W, stride, padding='SAME'), b))\n",
    "        mask = tf.sequence_mask(shape_list,tf.shape(conv)[1]) # make mask with batch x frame size\n",
    "        mask = tf.where(mask, tf.ones_like(mask,dtype=tf.float32), tf.zeros_like(mask,dtype=tf.float32))\n",
    "        mask=tf.tile(mask, tf.stack([tf.shape(conv)[2],1])) #replicate make with depth size\n",
    "        mask=tf.reshape(mask,[tf.shape(conv)[2], tf.shape(conv)[0], -1])\n",
    "        mask = tf.transpose(mask,[1, 2, 0])\n",
    "        print('Hi I am mask', mask)\n",
    "        conv=tf.multiply(conv,mask)\n",
    "        return conv\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi I am mask Tensor(\"transpose:0\", shape=(?, ?, ?), dtype=float32)\n",
      "Hi I am mask Tensor(\"transpose_1:0\", shape=(?, ?, ?), dtype=float32)\n",
      "Hi I am mask Tensor(\"transpose_2:0\", shape=(?, ?, ?), dtype=float32)\n",
      "Hi I am mask Tensor(\"transpose_3:0\", shape=(?, ?, ?), dtype=float32)\n",
      "Hi I am conv1 Tensor(\"Mul:0\", shape=(?, ?, 500), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-6-158168bd901d>:62: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "(?, 3000)\n",
      "(?, 1500)\n",
      "(?, 600)\n",
      "INFO:tensorflow:Restoring parameters from /home/disooqi/qmdis-post-processor-full/arabic_dialect_identification/acoustic/model/model910000.ckpt\n"
     ]
    }
   ],
   "source": [
    "emnet_validation = nn(x,y,y,s,softmax_num)\n",
    "sess2 = tf.Session()\n",
    "saver2 = tf.train.Saver()\n",
    "sess2.run(tf.global_variables_initializer())\n",
    "saver2.restore(sess2, model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
