{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import codecs\n",
    "from collections import Counter\n",
    "import random \n",
    "import numpy as np\n",
    "from numpy.random import permutation, shuffle, rand\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence count: 0\n",
      "set([])\n"
     ]
    }
   ],
   "source": [
    "sentences = list()\n",
    "labels = list()\n",
    "\n",
    "labels_dist = set()\n",
    "\n",
    "dataset = dict()\n",
    "#We will release training and testing data for the following Arabic dialects: \n",
    "# Egyptian, Gulf, Levantine, and North-African, and Modern Standard Arabic (MSA)\n",
    "\n",
    "with codecs.open('task2-train.txt') as training:\n",
    "    LAV = list()\n",
    "    MSA = list()\n",
    "    EGY = list()\n",
    "    GLF = list()\n",
    "    NOR = list()\n",
    "    for i, line in enumerate(training):\n",
    "        sentence_label = line.strip().split('\\t')\n",
    "        # sentences.append(sentence_label[0])\n",
    "        # labels.append(sentence_label[2])\n",
    "        \n",
    "        if sentence_label[2] == 'LAV':\n",
    "            LAV.append(sentence_label[0])\n",
    "        elif sentence_label[2] == 'MSA':\n",
    "            MSA.append(sentence_label[0])\n",
    "        elif sentence_label[2] == 'EGY':\n",
    "            EGY.append(sentence_label[0])\n",
    "        elif sentence_label[2] == 'GLF':\n",
    "            GLF.append(sentence_label[0])\n",
    "        elif sentence_label[2] == 'NOR':\n",
    "            NOR.append(sentence_label[0])\n",
    "        else:\n",
    "            print(sentence_label[0])\n",
    "    else:\n",
    "        print 'sentence count:', len(sentences)\n",
    "        print set(labels)\n",
    "        dataset['LAV'] = LAV\n",
    "        dataset['MSA'] = MSA\n",
    "        dataset['EGY'] = EGY\n",
    "        dataset['GLF'] = GLF\n",
    "        dataset['NOR'] = NOR\n",
    "        LAV = list()\n",
    "        MSA = list()\n",
    "        EGY = list()\n",
    "        GLF = list()\n",
    "        NOR = list()\n",
    "\n",
    "target_names = dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1758"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['LAV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.43379487001\n"
     ]
    }
   ],
   "source": [
    "average_word_len = 0;\n",
    "num_words = 0;\n",
    "for s in dataset['LAV'] + dataset['MSA'] + dataset['EGY'] + dataset['GLF'] + dataset['NOR']:\n",
    "    num_words += len(s.split(' '))\n",
    "    average_word_len += sum([len(w) for w in s.split(' ')])\n",
    "print float(average_word_len)/num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAV training dataset:  1583 , cross-validation set:  0 , test: 175\n",
      "MSA training dataset:  900 , cross-validation set:  0 , test: 99\n",
      "EGY training dataset:  1421 , cross-validation set:  0 , test: 157\n",
      "GLF training dataset:  1505 , cross-validation set:  0 , test: 167\n",
      "NOR training dataset:  1451 , cross-validation set:  0 , test: 161\n",
      "----------------------------------------------------------------------\n",
      "Total  ...  Training:  6860 , cross-validation data 0 , test:  759\n"
     ]
    }
   ],
   "source": [
    "def divide_dataset(dataset ,CV=True, train_perc=60 , CV_perc=20, test_perc=20):\n",
    "    if train_perc + CV_perc + test_perc != 100:\n",
    "        print 'the sum of percs is not 100'\n",
    "        return\n",
    "    samples_train = dict()\n",
    "    samples_cv = dict()\n",
    "    samples_test = dict()\n",
    "    \n",
    "    for dialect, sentences in dataset.items():\n",
    "        samples = permutation(sentences)\n",
    "        train_len = int(np.ceil(len(samples)*(train_perc/100.0)))\n",
    "        samples_train[dialect] = sentences[:train_len]\n",
    "        cv_len = 0\n",
    "        if CV:\n",
    "            cvp = CV_perc/(100.0-60)\n",
    "            cv_len = int(np.ceil((len(samples)-train_len) * cvp))\n",
    "            samples_cv[dialect] = sentences[train_len:train_len+cv_len]\n",
    "            samples_test[dialect] = sentences[train_len+cv_len:]\n",
    "        else:\n",
    "            samples_cv[dialect] = list()\n",
    "            samples_test[dialect] = sentences[train_len:]\n",
    "    else:\n",
    "        return samples_train, samples_cv, samples_test\n",
    "            \n",
    "\n",
    "train_set, cv_set, test_set = divide_dataset(dataset, CV=False, train_perc=90 ,CV_perc=0, test_perc=10)\n",
    "\n",
    "\n",
    "t,c,ts = 0,0,0\n",
    "for dial in ['LAV', 'MSA', 'EGY', 'GLF', 'NOR']:\n",
    "    t += len(train_set[dial])\n",
    "    c += len(cv_set[dial])\n",
    "    ts+= len(test_set[dial])\n",
    "    print dial, 'training dataset: ', len(train_set[dial]), ', cross-validation set: ', \\\n",
    "    len(cv_set[dial]),', test:', len(test_set[dial])\n",
    "    \n",
    "else:\n",
    "    print 70*'-'\n",
    "    print 'Total  ...  Training: ', t, ', cross-validation data', c, ', test: ', ts\n",
    "\n",
    "dataset_train = train_set['LAV']+train_set['MSA']+train_set['EGY']+train_set['GLF']+train_set['NOR']\n",
    "dataset_cv = cv_set['LAV']+cv_set['MSA']+cv_set['EGY']+cv_set['GLF']+cv_set['NOR']\n",
    "dataset_test = test_set['LAV']+test_set['MSA']+test_set['EGY']+test_set['GLF']+test_set['NOR']\n",
    "\n",
    "\n",
    "label_train = ['LAV' for x in train_set['LAV']] + ['MSA' for x in train_set['MSA']] +\\\n",
    "['EGY' for x in train_set['EGY']] + ['GLF' for x in train_set['GLF']]+['NOR' for x in train_set['NOR']]\n",
    "\n",
    "label_cv = ['LAV' for x in cv_set['LAV']] + ['MSA' for x in cv_set['MSA']] +\\\n",
    "['EGY' for x in cv_set['EGY']] + ['GLF' for x in cv_set['GLF']]+['NOR' for x in cv_set['NOR']]\n",
    "\n",
    "label_test = ['LAV' for x in test_set['LAV']] + ['MSA' for x in test_set['MSA']] +\\\n",
    "['EGY' for x in test_set['EGY']] + ['GLF' for x in test_set['GLF']]+['NOR' for x in test_set['NOR']]\n",
    "\n",
    "train_set, cv_set, test_set = 0,0,0\n",
    "#print len(label_train),len(label_cv),len(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_zipped = zip(dataset_train, label_train)\n",
    "random.shuffle(train_zipped)\n",
    "dataset_train, label_train = zip(*train_zipped)\n",
    "\n",
    "if dataset_cv:\n",
    "    cv_zipped = zip(dataset_cv, label_cv)\n",
    "    random.shuffle(cv_zipped)\n",
    "    dataset_cv, label_cv = zip(*cv_zipped)\n",
    "\n",
    "if dataset_test:\n",
    "    test_zipped = zip(dataset_test, label_test)\n",
    "    random.shuffle(test_zipped)\n",
    "    dataset_test, label_test = zip(*test_zipped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word count + Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  87.1 %\n",
      "Testing Acc:  57.58 %\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer() \n",
    "X_train = count_vect.fit_transform(dataset_train)\n",
    "X_test = count_vect.transform(dataset_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, label_train)\n",
    "\n",
    "train_pred = mnb.predict(X_train)\n",
    "test_pred = mnb.predict(X_test)\n",
    "\n",
    "#count_vect.vocabulary_.get(u'la')\n",
    "print 'Training Acc: ',np.around(np.mean(train_pred == label_train)*100,2), '%'\n",
    "print 'Testing Acc: ',np.around(np.mean(test_pred == label_test)*100,2), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF + Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  72.86 %\n",
      "Testing Acc:  44.14 %\n"
     ]
    }
   ],
   "source": [
    "# To avoid these potential discrepancies it suffices to divide the number of occurrences of each word in a document \n",
    "# by the total number of words in the document: these new features are called tf for Term Frequencies.\n",
    "tf_transformer = TfidfTransformer(use_idf=False) #.fit(X_train_counts)\n",
    "X_train = tf_transformer.fit_transform(X_train)\n",
    "X_test = tf_transformer.transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, label_train)\n",
    "\n",
    "train_pred = mnb.predict(X_train)\n",
    "test_pred = mnb.predict(X_test)\n",
    "\n",
    "#count_vect.vocabulary_.get(u'la')\n",
    "print 'Training Acc: ',np.around(np.mean(train_pred == label_train)*100,2), '%'\n",
    "print 'Testing Acc: ',np.around(np.mean(test_pred == label_test)*100,2), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf + Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  86.46 %\n",
      "Testing Acc:  49.14 %\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X_train = tfidf_vect.fit_transform(dataset_train)\n",
    "X_test = tfidf_vect.transform(dataset_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, label_train)\n",
    "# X_new_counts = count_vect.transform(docs_new)\n",
    "# X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "\n",
    "train_pred = mnb.predict(X_train)\n",
    "test_pred = mnb.predict(X_test)\n",
    "#actual = np.array(label_train, dtype='S3')\n",
    "print 'Training Acc: ',np.around(np.mean(train_pred == label_train)*100,2), '%'\n",
    "print 'Testing Acc: ',np.around(np.mean(test_pred == label_test)*100,2), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### tfidf + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  96.38 %\n",
      "Testing Acc:  56.26 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t = CountVectorizer() \n",
    "X_train = count_vect.fit_transform(dataset_train)\n",
    "X_test = count_vect.transform(dataset_test)\n",
    "\n",
    "logreg = LogisticRegression(C=1)\n",
    "logreg.fit(X_train, label_train)\n",
    "y_pred = logreg.predict(X_test)                  # .score(X_train, label_train)\n",
    "\n",
    "\n",
    "print 'Training Acc: ',np.around(logreg.score(X_train, label_train)*100,2), '%'\n",
    "print 'Testing Acc: ',np.around(logreg.score(X_test, label_test)*100,2), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfidf + Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  96.43 %\n",
      "Testing Acc:  59.82 %\n"
     ]
    }
   ],
   "source": [
    "clf = SGDClassifier()\n",
    "\n",
    "# count_vect = CountVectorizer() \n",
    "# X_train = count_vect.fit_transform(dataset_train)\n",
    "# X_test = count_vect.transform(dataset_test)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_train = tfidf_vect.fit_transform(dataset_train)\n",
    "X_test = tfidf_vect.transform(dataset_test)\n",
    "\n",
    "clf.fit(X_train, label_train)\n",
    "train_pred = clf.predict(X_train) \n",
    "y_pred = clf.predict(X_test) \n",
    "\n",
    "\n",
    "print 'Training Acc: ',np.around(np.mean(train_pred == label_train)*100,2), '%'\n",
    "print 'Testing Acc: ',np.around(np.mean(y_pred == label_test)*100,2), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF  + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Acc:  96.02 %\n",
      "Testing Acc:  59.29 %\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X_train = tfidf_vect.fit_transform(dataset_train)\n",
    "X_test = tfidf_vect.transform(dataset_test)\n",
    "\n",
    "my_C = 100\n",
    "\n",
    "# clf = svm.SVC()\n",
    "# clf.fit(X_train, label_train)\n",
    "# train_pred = clf.predict(X_train) \n",
    "# y_pred = clf.predict(X_test) \n",
    "\n",
    "clf_linear = svm.LinearSVC(C= 0.3)\n",
    "clf_linear.fit(X_train, label_train)\n",
    "train_pred = clf_linear.predict(X_train) \n",
    "y_pred = clf_linear.predict(X_test) \n",
    "\n",
    "print 'Training Acc: ',np.around(np.mean(train_pred == label_train)*100,2), '%'\n",
    "print 'Testing Acc: ',np.around(np.mean(y_pred == label_test)*100,2), '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF  + Neural Network\n",
    "https://github.com/timshenkao/StringKernelSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataset_train = ['We present a study on sentence-level Arabic Dialect Identification using the newly developed Multidialectal Parallel Corpus of Arabic (MPCA) – the first experiments on such data.', 'Using a set of surface features based on characters and words, we conduct three experiments with a linear Support Vector Machine classifier and a meta-classifier using stacked generalization – a method not previously applied for this task.', 'We first conduct a 6-way multi-dialect classification task in the first experiment, achieving 74% accuracy against a random baseline of 16.7% and demonstrating that meta-classifiers can large performance increases over single classifiers.', 'The second experiment investigates pairwise binary dialect classification within the corpus, yielding results as high as 94%, but also highlighting poorer results between closely related dialects such as Palestinian and Jordanian (76%).', 'Our final experiment conducts cross-corpus evaluation on the widely used Arabic Online Commentary (AOC) dataset and demonstrates that despite differing greatly in size and content, models trained with the MPCA generalize to the AOC, and vice versa.', 'Using only 2,000 sentences from the MPCA, we classify over 26k sentences from the radically different AOC dataset with 74% accuracy.', \n",
    "# 'We also use this data to classify a new dataset of MSA and Egyptian Arabic tweets with 97% accuracy.', 'We find that character n-grams are a very informative feature for this task, in both within-and cross-corpus settings.', 'Contrary to previous results, they outperform word n-grams in several experiments here.', 'Several directions for future work are outlined.']\n",
    "\n",
    "# dataset_test = ['The  Arabic  language,  the  official  language  of  more  than 20 countries,  is  comprised  of  many  regional  dialects  with the Modern Standard Arabic (MSA) variety having the role of a common dialect across the Arabic-speaking population.', 'Arabic  is  a  morphologically  sophisticated  language  withmany  morphemes  that  can  appear  as  prefixes,  suffixes  oreven  circumfixes.',  'These  mark  grammatical  information  including  case,  number,  gender,  and  definiteness,  amongst others.',  'This  leads  to  a  sophisticated  morphotactic  system.', \n",
    "# 'Its orthography is very different to English with right-to-left text  that  uses  connective  letters.', 'Moreover,  this  is  further complicated  due  to  the  presence  of  word  elongation,  common ligatures, zero-width diacritics and allographic variants resulting  in  a  degree  of  orthographic  ambiguity.', ' All  ofthese properties pose a challenge for NLP [1].',\n",
    "# 'Arabic Dialect Identification using a Parallel Multidialectal Corpus.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(label_test, y_pred, labels=[ 'MSA', 'LAV', 'EGY', 'GLF', 'NOR'])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    #tick_marks = np.arange(len(iris.target_names))\n",
    "    #plt.xticks(tick_marks, iris.target_names, rotation=45)\n",
    "    #plt.yticks(tick_marks, iris.target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# Compute confusion matrix\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples\n",
    "# in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<pre>\n",
    "```\n",
    "\n",
    "| This | is |\n",
    "|------|------|\n",
    "|   a  | table|\n",
    "\n",
    "```\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
