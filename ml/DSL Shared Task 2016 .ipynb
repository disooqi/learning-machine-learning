{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://ttg.uni-saarland.de/vardial2016/dsl2016.html\n",
    "### https://en.wikipedia.org/wiki/SMART_Information_Retrieval_System\n",
    "### https://groups.google.com/forum/#!forum/dsl-shared-task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence count: 7619\n",
      "set(['LAV', 'MSA', 'EGY', 'GLF', 'NOR'])\n"
     ]
    }
   ],
   "source": [
    "sentences = list()\n",
    "labels = list()\n",
    "\n",
    "labels_dist = set()\n",
    "\n",
    "LAV = list()\n",
    "MSA = list()\n",
    "EGY = list()\n",
    "GLF = list()\n",
    "NOR = list()\n",
    "\n",
    "#We will release training and testing data for the following Arabic dialects: \n",
    "# Egyptian, Gulf, Levantine, and North-African, and Modern Standard Arabic (MSA)\n",
    "\n",
    "with codecs.open('task2-train.txt') as training:\n",
    "    for i, line in enumerate(training):\n",
    "        sentence_label = line.strip().split('\\t')\n",
    "        sentences.append(sentence_label[0])\n",
    "        labels.append(sentence_label[2])\n",
    "        \n",
    "        if sentence_label[2] == 'LAV':\n",
    "            LAV.append(sentence_label[0])\n",
    "        elif sentence_label[2] == 'MSA':\n",
    "            MSA.append(sentence_label[0])\n",
    "        elif sentence_label[2] == 'EGY':\n",
    "            EGY.append(sentence_label[0])\n",
    "        elif sentence_label[2] == 'GLF':\n",
    "            GLF.append(sentence_label[0])\n",
    "        elif sentence_label[2] == 'NOR':\n",
    "            NOR.append(sentence_label[0])\n",
    "        else:\n",
    "            print(sentence_label[0])\n",
    "    else:\n",
    "        print 'sentence count:', len(sentences)\n",
    "        print set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$>ny tlthA stHZY >h yA xyr Aldyn wlkn >h',\n",
       " \"$A' Allh wynzl AlklyAt >h lA nErD Elyhm wAlfkrp wnntZr wTAEtnA wnHAwl <nh lm ytm ElY mn dlwqt\",\n",
       " '$A*A b|t$h >nt zrt lyh l>n h*A Ebd Allh bn mHmwd SAHb AlmAl wSAHb AltjArp wlA tfkr >nt >nh bryp wjwyp lmnkwby wwSf fyh wbyqwl Hb AlnAs tEAlwA h*A wld Alb$r Ally mvlA h*h Alsnp trknAh wnEyd mnh >bw Ely jdA mnkm',\n",
       " '$Ahd AlgrAfyk tfAqmh',\n",
       " \"$Ahd tglb wAjb |xr mr Ebr EddA mn brnAmjh <HnA wyAhm lA ymnE xrwj bAlb$r ftzydh whlA Em lxrwqAt AlHq Al$yx xAld Hqq mEy lA yglq fyjb hdf AlnAtw bAlAxtyAr mn Altwqf lA tqAs bqyt Endk nsmH lkl $y' HtY tqrr trHb\",\n",
       " \"$AhdnA Edyd Al>HdAv ElY xlfyp mnE Al$rq En AntmA' dyny b$ yEqd m&tmr >h vAlv yzyl kl bAb kAnt sbqth bED AlmHAwlAt fy nSb AlxyAm AldEwyp bED AlmsAjd >yh AHtSlt ndwAt SHfyp m$ddyn rbmA fy twns wAllh fyh bED AlDbAbyp hl >nh >Hmlhm bAlHq mhddyn fy xTAb dyny mt$dd w>y dwr llxTAb Aldyny b$y' sAm fy nb* AlEnf wAltTrf wAltSdy ll<rhAb fy h*A Altqryr y$wfwA mE bEDnA fy mlxSh kl Ally b$ nHky fy b$ ykwn lnA Ewdp mE mjmwEp mn Almdxnyn fy h*A Al$>n b$ nHky >kvr tEmqA\",\n",
       " '$AHnp',\n",
       " '$AmbAs >nA >kyd Alxmsp bryng mn$q Dmn mn Al>sf kAnt lltbrk <ynAs >nA fy kl AlHAlAt qEd jmEp qAl lnA HAjp qlp lmnTqp',\n",
       " \"$AnzAy sbq wH*rt <nk tbtEd En AxtbA'\",\n",
       " '$Ark br>yk fy AlmxAzn AHtkAr Hml yEny']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOR', 'EGY', 'GLF', 'GLF', 'NOR', 'NOR', 'NOR', 'NOR', 'GLF', 'GLF']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def from_buck_to_utf8(text):\n",
    "    b2a = {'A': u'\\u0627',  '<': u'\\u0625',  '|': u'\\u0622',  '>': u'\\u0623',  \"'\": u'\\u0621',  'b': u'\\u0628',  \n",
    "           't': u'\\u062a',  'v': u'\\u062b',  'j': u'\\u062c',  'H': u'\\u062d',  'x': u'\\u062e',  'd': u'\\u062f',  \n",
    "           '*': u'\\u0630',  'r': u'\\u0631',  'z': u'\\u0632',  's': u'\\u0633',  '$': u'\\u0634',  'S': u'\\u0635',  \n",
    "           'D': u'\\u0636',  'T': u'\\u0637',  'Z': u'\\u0638',  'E': u'\\u0639',  'g': u'\\u063a',  'f': u'\\u0641',  \n",
    "           'q': u'\\u0642',  'k': u'\\u0643',  'l': u'\\u0644',  'm': u'\\u0645',  'n': u'\\u0646',  'h': u'\\u0647',  \n",
    "           'w': u'\\u0648',  'y': u'\\u064a',  'Y': u'\\u0649',  'p': u'\\u0629',  '&': u'\\u0624',  '}': u'\\u0626',  \n",
    "           'a': u'\\u064e',  'F': u'\\u064b',  'u': u'\\u064f',  'N': u'\\u064c',  'i': u'\\u0650',  'K': u'\\u064d',  \n",
    "           'o': u'\\u0652',  '~': u'\\u0651'}\n",
    "    text = text.strip().split()\n",
    "    tmp_sentence = list()\n",
    "    for word in text:\n",
    "        tmp_word = list()\n",
    "        for c in word:\n",
    "            tmp_word.append(b2a.get(c,c))\n",
    "        else:\n",
    "            tmp_sentence.append(''.join(tmp_word))\n",
    "    else:\n",
    "        return ' '.join(tmp_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "utf8 = [from_buck_to_utf8(text) for text in sentences[:10]]\n",
       "\n",
       "for utf8_sentence in utf8:\n",
       "    print <h4 align=\"right\">utf8_sentence<h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "utf8 = [from_buck_to_utf8(text) for text in sentences[:10]]\n",
    "\n",
    "for utf8_sentence in utf8:\n",
    "    print <h4 align=\"right\">utf8_sentence<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'LAV': 1758, 'GLF': 1672, 'NOR': 1612, 'EGY': 1578, 'MSA': 999})\n"
     ]
    }
   ],
   "source": [
    "print Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شارون أعلن حرب مفتوحة شارون يريد إبادة الشعب الفلسطيني واغتيال القادة الفلسطينيين والكوادر الفلسطينيين وجه من خلال ما هذه الجريمة اليوم رسالة لكل الشعب الفلسطيني والأمة العربية بأنه أعلن الحرب وحرب مفتوحة\n",
      "شباب حرموا التعليم وحرموا الثقافة وسليمه كافة الحقوق لم يعد أمامهم إلا أن ينتهي مهنة باستعراض القوة أو بسط السيطرة والنفوذ فواجب وتجاوبا مع سلطة جديدة تحاول أن تجد أدوات التي تسيطر بها فهي لا تستطيع أن تسيطر بالسياسة ولا بالثقافة ولا بأي منطق وإنما تسيطر بالبطل\n",
      "شهد السكندريون نظاما حديديا يتهاوى ورائي سنية فر رئيسا طالما قبضة بقواه الأمنية على شعبه ولم تكن القبضة الأمنية على السكندريين أقل رغم فى ودماء خالد سعيد\n",
      "شكرا الزميل محمد العلمي وقد انضم إلينا مشكورا من أمام المحكمة العليا في واشنطن أه أه أرحب مجددا بضيفي الدكتور صفا رفقة وتوم حرب من أورلاندو فلوريدا الدكتور رفقة بداية أنت كطبيب هل هذا القرار الذي أصدرته المحكمة العليا يخدم مجموع المجتمع الأمريكي أن أنه يقوض مستقبل الأجيال القادمة كما يقول الجمهوريين\n",
      "شكرا جزيلا النفوذ من وقتكم أكثر من هذا ومشاهدينا نتوقف إذا مع عينة أخرى أيضا أكثر تنوعا من آراء المدرسين عن حالة التعليم في مصر\n"
     ]
    }
   ],
   "source": [
    "for sentence in MSA[:5]:\n",
    "    print from_buck_to_utf8(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شارك\n",
      "شايف ليش ما أنت تصنع للمواد وسيرت بكل مهام للبلد ومعامل للدول المجاورة واللي بعد المجاورة كما وأحسن ما تدفع حق بالعملة الصعبة أضعف تكلفتها\n",
      "شعبي كاسح من كثير عطشا\n",
      "شعور ناحية الحق عليك أن تراها العماري\n",
      "شفنا بيعملوا بالشكل اللي بيحبوا\n"
     ]
    }
   ],
   "source": [
    "for sentence in LAV[:5]:\n",
    "    print from_buck_to_utf8(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "شاء الله وينزل الكليات أه لا نعرض عليهم والفكرة وننتظر وطاعتنا ونحاول إنه لم يتم على من دلوقت\n",
      "شارك طبعا من استهلاك نوع مختلف عن الثاني فى بالدين أحدث تلفيات في أكثر من حاجة ما ننظر مناسبة كمراكز المجال الثاني كنا نحتاج لشخصية صلاح بنشوف حاجات تشابك لكل وحدتنا وصل اليوم عن طريق نتفاوض ما بيصيرش إنا في سيتسم صايل فبص ناصيته ويجب من من هنا لهنا محتجين على غرار واتصلنا به ووجدنا صلاح من الواضح دية اللي إحنا كنا محتاجينها تصلح ضروري جدا في الشركة وذكر طبعا كان أقرب وأسهل طريق نحن نقدر نوصل من خلال\n",
      "شارك تفسر أي شيء بضاعته واحد أي شيء مما يفسر في كلياته وليست رسمية فالإنسان أكثر منه هو أيديولوجي أكثر من 80 أه يعني شكل لشخصية مستقلة متعددة الجوانب\n",
      "شارك\n",
      "شباب الألتراس كان دوره مهم ملهم في ثورة خمسة وعشرين\n"
     ]
    }
   ],
   "source": [
    "for sentence in EGY[:5]:\n",
    "    print from_buck_to_utf8(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in MSA sentences:  48987\n",
      "Unique words in MSA sentences: 13607\n",
      "في 1739\n",
      "من 1168\n",
      "أن 723\n",
      "على 697\n",
      "إلى 534\n",
      "هذه 384\n",
      "هذا 356\n",
      "التي 354\n",
      "أه 326\n",
      "عن 281\n",
      "ما 272\n",
      "لا 215\n",
      "الذي 214\n",
      "مع 197\n",
      "يعني 190\n",
      "كان 187\n",
      "ال 163\n",
      "أو 163\n",
      "لم 159\n",
      "هل 147\n"
     ]
    }
   ],
   "source": [
    "MSA_words = list()\n",
    "for sentence in MSA:\n",
    "    tokens = from_buck_to_utf8(sentence).split()\n",
    "    MSA_words.extend(tokens)\n",
    "    \n",
    "print 'Total words in MSA sentences: ', len(MSA_words)\n",
    "print 'Unique words in MSA sentences:', len(set(MSA_words))\n",
    "MSA_freq = Counter(MSA_words)\n",
    "for word, freq in MSA_freq.most_common(20):\n",
    "    print word, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in EGY sentences:  84949\n",
      "Unique words in EGY sentences: 20836\n",
      "في 2553\n",
      "من 1629\n",
      "يعني 1203\n",
      "على 1091\n",
      "أه 897\n",
      "ما 764\n",
      "أن 693\n",
      "أو 623\n",
      "اللي 590\n",
      "أنا 569\n",
      "كان 537\n",
      "لا 507\n",
      "هو 495\n",
      "هذا 474\n",
      "إن 471\n",
      "ال 452\n",
      "إحنا 430\n",
      "إلى 412\n",
      "مش 393\n",
      "إنه 383\n"
     ]
    }
   ],
   "source": [
    "EGY_words = list()\n",
    "for sentence in EGY:\n",
    "    tokens = from_buck_to_utf8(sentence).split()\n",
    "    EGY_words.extend(tokens)\n",
    "    \n",
    "print 'Total words in EGY sentences: ', len(EGY_words)\n",
    "print 'Unique words in EGY sentences:', len(set(EGY_words))\n",
    "EGY_freq = Counter(EGY_words)\n",
    "for word, freq in EGY_freq.most_common(20):\n",
    "    print word, freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in LAV sentences:  66219\n",
      "Unique words in LAV sentences: 19198\n",
      "في 1362  |= =|  من 1302  |= =|  ما 935  |= =|  على 877  |= =|  يعني 857  |= =|  أه 604  |= =|  اللي 457  |= =|  أنا 455  |= =|  لا 444  |= =|  إنه 441  |= =|  كان 419  |= =|  هذا 418  |= =|  أن 417  |= =|  كل 394  |= =|  أو 388  |= =|  عن 368  |= =|  مع 317  |= =|  هو 304  |= =|  عم 293  |= =|  ال 271  |= =| \n"
     ]
    }
   ],
   "source": [
    "LAV_words = list()\n",
    "for sentence in LAV:\n",
    "    tokens = from_buck_to_utf8(sentence).split()\n",
    "    LAV_words.extend(tokens)\n",
    "    \n",
    "print 'Total words in LAV sentences: ', len(LAV_words)\n",
    "print 'Unique words in LAV sentences:', len(set(LAV_words))\n",
    "LAV_freq = Counter(LAV_words)\n",
    "\n",
    "\n",
    "for word, freq in LAV_freq.most_common(20):\n",
    "    print word, freq, ' |= =| ',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in NOR sentences:  51593\n",
      "Unique words in NOR sentences: 20271\n",
      "في 1040  |= =|  من 672  |= =|  ما 568  |= =|  أه 516  |= =|  يعني 489  |= =|  اللي 369  |= =|  على 366  |= =|  كان 301  |= =|  كل 285  |= =|  أن 250  |= =|  مش 225  |= =|  أو 214  |= =|  هذا 210  |= =|  مع 201  |= =|  هو 196  |= =|  هي 178  |= =|  أنا 178  |= =|  الله 177  |= =|  لا 173  |= =|  ال 172  |= =| \n"
     ]
    }
   ],
   "source": [
    "NOR_words = list()\n",
    "for sentence in NOR:\n",
    "    tokens = from_buck_to_utf8(sentence).split()\n",
    "    NOR_words.extend(tokens)\n",
    "    \n",
    "print 'Total words in NOR sentences: ', len(NOR_words)\n",
    "print 'Unique words in NOR sentences:', len(set(NOR_words))\n",
    "NOR_freq = Counter(NOR_words)\n",
    "for word, freq in NOR_freq.most_common(20):\n",
    "    print word, freq, ' |= =| ',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in GLF sentences:  64081\n",
      "Unique words in GLF sentences: 17842\n",
      "في 1852  |= =|  من 1306  |= =|  يعني 1009  |= =|  ما 698  |= =|  أن 666  |= =|  على 666  |= =|  هذا 618  |= =|  أه 494  |= =|  اللي 457  |= =|  لا 447  |= =|  هذه 422  |= =|  أنا 390  |= =|  أو 372  |= =|  إلى 326  |= =|  ال 291  |= =|  عن 288  |= =|  هو 281  |= =|  كان 241  |= =|  مع 233  |= =|  كل 228  |= =| \n"
     ]
    }
   ],
   "source": [
    "GLF_words = list()\n",
    "for sentence in GLF:\n",
    "    tokens = from_buck_to_utf8(sentence).split()\n",
    "    GLF_words.extend(tokens)\n",
    "    \n",
    "print 'Total words in GLF sentences: ', len(GLF_words)\n",
    "print 'Unique words in GLF sentences:', len(set(GLF_words))\n",
    "GLF_freq = Counter(GLF_words)\n",
    "for word, freq in GLF_freq.most_common(20):\n",
    "    print word, freq, ' |= =| ',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in all sentences:  315829\n",
      "Unique words in all sentences: 55992\n",
      "في 1852  |= =|  من 1306  |= =|  يعني 1009  |= =|  ما 698  |= =|  أن 666  |= =|  على 666  |= =|  هذا 618  |= =|  أه 494  |= =|  اللي 457  |= =|  لا 447  |= =|  هذه 422  |= =|  أنا 390  |= =|  أو 372  |= =|  إلى 326  |= =|  ال 291  |= =|  عن 288  |= =|  هو 281  |= =|  كان 241  |= =|  مع 233  |= =|  كل 228  |= =| \n"
     ]
    }
   ],
   "source": [
    "sentences\n",
    "words = list()\n",
    "for sentence in sentences:\n",
    "    tokens = from_buck_to_utf8(sentence).split()\n",
    "    words.extend(tokens)\n",
    "    \n",
    "print 'Total words in all sentences: ', len(words)\n",
    "print 'Unique words in all sentences:', len(set(words))\n",
    "freq = Counter(GLF_words)\n",
    "for word, freq in freq.most_common(20):\n",
    "    print word, freq, ' |= =| ',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Name | Description | age         \n",
      "| :- |-------------: | :-:\n",
      "|Mary| She is a nice girl.  | 20\n",
      "| Jackie Junior | He is a very naughty boy. | 5\n"
     ]
    }
   ],
   "source": [
    "print '| Name | Description | age         '\n",
    "print '| :- |-------------: | :-:'\n",
    "print '|Mary| She is a nice girl.  | 20'\n",
    "print '| Jackie Junior | He is a very naughty boy. | 5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 align=\"right\">This is a centered header</h3> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<h3 align=\"right\">This is a centered header</h3> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EGY_doc = '. '.join(EGY)\n",
    "LAV_doc = '. '.join(LAV)\n",
    "NOR_doc = '. '.join(NOR)\n",
    "GLF_doc = '. '.join(GLF)\n",
    "MSA_doc = '. '.join(MSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (5, 46027))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vect.fit_transform([EGY_doc,GLF_doc,LAV_doc,NOR_doc,MSA_doc])\n",
    "type(X_train_tfidf), X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tfidf[:,:5].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.matrixlib.defmatrix.matrix"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tfidf.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrixlib.defmatrix.matrix'>\n",
      "(5, 46027)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.00386453,  0.00124612,  0.        ,  0.        ,  0.00110593],\n",
       "        [ 0.00316051,  0.00086232,  0.        ,  0.00051021,  0.        ],\n",
       "        [ 0.00371368,  0.        ,  0.00041919,  0.        ,  0.        ],\n",
       "        [ 0.00407152,  0.00144415,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.0010686 ,  0.00126343,  0.00045233,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://www.markhneedham.com/blog/2015/02/15/pythonscikit-learn-calculating-tfidf-on-how-i-met-your-mother-transcripts/\n",
    "dense = X_train_tfidf.todense()\n",
    "print type(dense)\n",
    "print dense.shape\n",
    "\n",
    "dense[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGY:  17640\n",
      "LAV:  16340\n"
     ]
    }
   ],
   "source": [
    "EGY_vec = dense[0].tolist()[0]\n",
    "EGY_phrase_scores = [pair for pair in zip(range(0, len(EGY_vec)), EGY_vec) if pair[1] > 0]\n",
    "print 'EGY: ', len(EGY_phrase_scores)\n",
    "\n",
    "LAV_vec = dense[2].tolist()[0]\n",
    "LAV_phrase_scores = [pair for pair in zip(range(0, len(LAV_vec)), LAV_vec) if pair[1] > 0]\n",
    "print 'LAV: ', len(LAV_phrase_scores)\n",
    "\n",
    "GLF_vec = dense[1].tolist()[0]\n",
    "GLF_phrase_scores = [pair for pair in zip(range(0, len(GLF_vec)), GLF_vec) if pair[1] > 0]\n",
    "\n",
    "NOR_vec = dense[3].tolist()[0]\n",
    "NOR_phrase_scores = [pair for pair in zip(range(0, len(NOR_vec)), NOR_vec) if pair[1] > 0]\n",
    "\n",
    "MSA_vec = dense[4].tolist()[0]\n",
    "MSA_phrase_scores = [pair for pair in zip(range(0, len(MSA_vec)), MSA_vec) if pair[1] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46027"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf_vect.get_feature_names()\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "َل                   0.613933156569\n",
      "في                   0.459703310656\n",
      "من                   0.316715731415\n",
      "يeني                 0.21131948136\n",
      "eلي                  0.20587400844\n",
      "مَ                   0.159675318833\n",
      "نَ                   0.131042670901\n",
      "لَ                   0.111368704225\n",
      "نه                   0.10943643964\n",
      "َللي                 0.103639645887\n",
      "كَن                  0.0980185125509\n",
      "هنَ                  0.0952079458828\n",
      "كل                   0.0925730396314\n",
      "لي                   0.0890598312963\n",
      "هو                   0.087830208379\n",
      "مe                   0.0655213354507\n",
      "بeد                  0.061656806282\n",
      "eن                   0.0593732208642\n",
      "جدَ                  0.0576166166966\n",
      "مسر                  0.0502388791928\n"
     ]
    }
   ],
   "source": [
    "sorted_EGY_phrase_scores = sorted(EGY_phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_EGY_phrase_scores][:20]:\n",
    "    #print from_buck_to_utf8(phrase), score\n",
    "    print(u'{0: <20} {1}'.format(from_buck_to_utf8(phrase), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_LAV_phrase_scores = sorted(LAV_phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_LAV_phrase_scores][:20]:\n",
    "    #print from_buck_to_utf8(phrase), score\n",
    "    print(u'{0: <20} {1}'.format(from_buck_to_utf8(phrase), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "َل                   0.55779815066\n",
      "في                   0.435652570224\n",
      "من                   0.291520785309\n",
      "مَ                   0.267091669221\n",
      "يeني                 0.199504448046\n",
      "eلي                  0.167746597133\n",
      "كل                   0.158789254568\n",
      "َللي                 0.150646215872\n",
      "كَن                  0.138431657828\n",
      "نه                   0.092423489197\n",
      "نَ                   0.0920163372622\n",
      "لَ                   0.0887591217839\n",
      "مe                   0.0830589946969\n",
      "هو                   0.0814303869577\n",
      "لي                   0.0761374118054\n",
      "هنَ                  0.0753231079359\n",
      "لك                   0.0749159560011\n",
      "هي                   0.0745088040663\n",
      "َلله                 0.0720658924576\n",
      "فيهَ                 0.0574084228052\n"
     ]
    }
   ],
   "source": [
    "sorted_NOR_phrase_scores = sorted(NOR_phrase_scores, key=lambda t: t[1] * -1)\n",
    "for phrase, score in [(feature_names[word_id], score) for (word_id, score) in sorted_NOR_phrase_scores][:20]:\n",
    "    #print from_buck_to_utf8(phrase), score\n",
    "    print(u'{0: <20} {1}'.format(from_buck_to_utf8(phrase), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arz_test = u'''lyh lmA tHb Hd mn qlb+k yTlE wATy lyh lmA tlEb ElY wAHd yTlE b+yHb+k lyh Ally h+ymwt Ely+k <n+t m$ TAyq+h w+Ally h+tmwt Ely+h m$ TAyq+k Ejb+t l+k yA zmn \n",
    "Al+Hmd l+Allh yA jdEAn Al+frsAn Ally Atmsk+wA End stAd AlqAhr+p xd+wA <xlA' sbyl rb+nA kbyr .. bqY l+nA 7 snyn Zlm w+qhr dh yrDy myn ؟؟؟؟  Al+Hmd  l+Allh \n",
    "Al+wAHd lmA b+ynAm ktyr ، b+yHlm b+>HlAm - hy fy Al+>glb hlAws >w HAj+At tAny+p ، bs Al+mhm m$ >HlAm yEny - mA l+hm+$ >y ElAq+p b+bED ، mttAly+p ، w+gyr mnTqy+p . \n",
    "Al+dnyA dy EbAr+p En AmtHAn w+<HnA fy+h ywm mA Al+AmtHAn dh b+yxlS HyA+p Al+<nsAn kmAn b+txlS sAE+t+hA bqY b+yrwH yjyb ntyj+t+h .. \n",
    "kn+tu xAyf Alsysy yTlE *ky w+mA ytr$H+$ ,, Al+Hmd l+Allh Al+HmAr h+ylbs :D \n",
    "mA bqy+to+$ m$kl+p <n+hm yDAyq+wA+k w+lA HtY yzEl+wA+k EAdy >Sl+A ، Al+m$kl+p <n+k kn+ta fAkr+hm HAj+p tAny+p gyr kdh  dnyA  |h  w+Allh \n",
    "<HsAs Hlw lmA tlAqy Hd $bh+k fy HAj+t+At ktyr+p , w+yhtm b+nfs Al+HAj+t+At Ally b+tHb+hA . fAkr+h tw>m tw>m :-D \n",
    "( 2 ) tyj+y ntklm w+nqwl kAm nSyH+p ElY kAm klm+p Hlw+p ElY Hb+p >y klAm El$An kAm rytwyt \n",
    "dAym+A Al+wAHd  b+yqSr fy Hq nAs  tstAhl w+ys>l ElY  nAs  mA tstAhl+$ :-( \n",
    "ybqY mA tnAm+y+$ w+xl+y+ky qAEd+p w+Ashr+y brDh l+Hd mA tfSl+y xAlS bEd kdh nAm+y b+Al+lyl\n",
    "<n+t mESwm mn Al+glT ؟ ! lA ؟ ! Tyb lyh bqY b+tHss+ny lmA b+>glT <n dy nhAy+p Al+EAlm yEny ! \n",
    "<n+tw m$ mtxyl+yn <n bkr+p Al+kly+p <zAy ... >nA b+>m$y >stxbY mn Al+nAs Ally mA b+>Hb+hA+$ w+dwl ktyr \n",
    "dy Hqyq+p l+Al+>sf Al+wAHd bqY b+yqwl >lfAZ mA l+hA+$ >y ElAq+p b+trby+t+h >bw+yA lw Erf h+ydbH+ny $qY Emr+h mn+hm l+Allh Al+bArd+yn \n",
    ">wqAt b+>$wf HAj+t+At gryb+p b+>xAf >qwl <n+hA gryb+p >Hsn Al+nAs tqwl Ely+yA gryb w+dh bqY Al+gryb fy Al+mwDwE !! \n",
    ">nA lmA Hd ys>l+ny brj+k <yh b+>tksf >qwl l+h Al+E*rA' b+SrAH+p >HA >Sl+A myn Ally smY Al+>brAj dy \n",
    ">nA glTAn+p <n+y smE+t klAm mAmA njwY lmA qAl+t sAmH yA sAmH sAmH xl+y+k msAmH sAmH kAn lAzm y>xd+wA b+Al+jzm+p <HnA jyl AtrbY glT \n",
    " <n+t  m$  $wr lmA t$rb sjAyr El$An twry Al+bnAt <n+k rAjl \n",
    "Al+mwDwE yA bn+y m$ $xSy , >nA mA b+>vq+$ fy mnbh Al+mwbAyl btAE+y .. f+l+k >n ttxyl bqY \n",
    "gAlbA HAl+p mn Al+Akt}Ab Al+$dyd hy b+tkwn rd s&Al .. hw >nA lw jrY l+y HAj+p h+>frq mE myn ؟ \n",
    "Al+m$Akl dAym+A b+tbd> lmA tqrb mn >y Hd zyAd+p En Al+lzwm , Al+ElAq+t+At Al+sTHy+p qAdr+p tHmy+nA mn HAj+t+At ktyr . \n",
    "kl+h yHDr hdy+p Eyd Al+>m . bws+wA <yd >mhAt+km w+A$kr+wA rb+nA <n+hm EAy$+yn wsT+nA \n",
    "EArf+yn <n+tw Al+$xSy+p Ally b+tyjy fy wsT EyAT+k w+tqwl l+k <n+t $kl+k kywt qwy w+>nt b+tEyT w+y$d fy xdwd+k Al+EAlm dy h+tmwt mHrwq+p :D \n",
    "<HnA m$ EAyz+yn nmwt nfs+nA .. <HnA fy+h HAj+At mEyn+p fy HyA+t+nA nfs+nA nmwt+hA \n",
    ">nA mHtAj+p >jyb $xS lbnAny ytklm mEA+yA fy >y klAm El$An lhj+t+hm b+tbsT+ny \n",
    "mA Hd+$ mHtAj mn Hd HAj+p Al+HAl+p 100 fl w+mrDy+p Al+fkr+p bs fy Al+tqdyr w+dh m$ b+flws dh kbyr+h s&Al b+SAfy ny+p \n",
    "Tyb Al+Eyb fy myn ؟ fy Al+fyzyA ؟ lA El$An fy+h nAs b+tfhm+hA . Tyb fy Al+mstr ؟ lA El$An fy+h nAs b+tfhm+h . ybqY Al+Eyb fy+A >nA w+Hsb+y Allh w+nEm Al+wkyl ! \n",
    ">nA EArf+p <n+k h+tstgrb+y Al+twyt+p dy .... bs >nA fElA mHtAj+p msAEd+p mn dktwr >mrAD nfsy+p w+m$ EArf+p Asm dktwr kwys \n",
    "lA lw smH+t :D ,, >nA El$An mA b+>Erf+$ >kdb b+>kH :D ,, fy+h nAs tAny+p b+tkdb w+mA b+yrm$ l+hA+$ rm$ :D q$T+p \n",
    "w+Allh hy m$Ark+p bs El$An mwlly frHAn+p <nmA <HnA >hlAwy+p HtY Al+nxAE w+hy dy Al+rwH Al+ryADy+p \n",
    "ywm frH+k <n+t b+txtAr myn yjy l+k , bs ywm mwt+k nAs mEyn+p hy Ally h+txtAr tyj+y ! \n",
    "kAn b+yTlE mwnwlwjst ElY x$b+p Al+msrH byn fSwl Al+rwAy+p ysly Al+jmhwr . Al+mr+p dy TlE mbt*l . rb+nA xd+h Al+Hmd l+Allh nrjE l+Al+jd bqY\n",
    "yA rb >nA m$ EAyz >jyb mjmwE El$An+y ، >nA EAyz >jyb mjmwE El$An >bw+yA w+>m+y w+El$An flws Al+drws dy m$ mAl HrAm yEny !  vAnwy+p  EAm+p \n",
    ">nA >xw+yA sryr+h b+ybqY fy+h kl HAj+p b+ybqY nAym w+HwAly+h >kl w+fAkh+p w+qzAyz myAh w+$rAb+At w+mwbAyl+h w+Al+lAb twb w+Al+rymwt >y HAj+p DAyE+p fy Al+byt b+nlAqy+hA \n",
    "h+yEjb by+ky El$An $kl+k w+h+yEjb by+ky El$An $xSy+t+k bs fy Al+|xr h+ytqdm l+k El$An >xlAq+k bs \n",
    "w+>y Hd h+yHkm mSr h+>dEy l+h rb+nA ywfq+h l+Al+SH El$An EAyz+p bld+y tbqy >Hsn w+mA dAm Al+nAs mbswT+p w+EAyz+Ah rb+nA ywfq+h w+ywfq+nA mEA+h \n",
    "lw Hby+t Hd mA t>xd+$ r>y Al+nAs fy+h El$An <n+t Ally Axtr+t+h m$ Al+nAs \n",
    "Al+HAl+p Al+zft Ally Al+wAHd b+ybqY fy+hA bq+t mlAzm+Ah ElY Twl ! rb+nA Al+mEyn \n",
    ">nA wSl+t l+mrHl+p <n+y mmkn >nAm w+>nA wAqf+p zy Al+HSn+p EAdy :D \n",
    "m$kl+p ktyr mn Al+nAs <n+hA Aftkr+t Al+vwr+p HAj+p sEyd+p w+lTyf+p lA dy mn >qsY Al+tjArb Ally b+tmr b+bld \n",
    "$Ewr EAlm+y lA ymAvl+h $Ewr lmA ttfAj} <n Al+nhArd+p Al+xmys m$ Al+>rbE :) b+tHSl ktyr \n",
    "h+tfDl+y kdh ktyr ؟! w+ﻻ h+yrjE HAj+p w+ﻻ h+yqdm HAj+p . AtxlS+y mn Al+slby+At dy w+AstmtE+y b+HyA+t+k :) w+dy >ql HAj+p tqdr+y tqdm+y+hA l+Ally b+yHb+w+ky \n",
    "mA tns+wA+$ Al+brsym Ally kAn wrA+h fy Al+xlfy+p dy ly+hA mEnY kbyr \n",
    "wSwl >wl mr$H r}Asy l+mqr Al+ElyA .. w+y&kd : brnAmj+y fy dmAg+y > Abtdy+nA Al+hbl w+Al+Ek . dmAg+k myn yA Em ؟ kbr dmAg+k $wy+p Tyb \n",
    "Al+nwr qTE Al+nhArd+p >ktr mA jh dh w+ls+p Al+tkyyf+At mA A$tgl+t+$ w+bkr+p t$wf+wA mSr :(  mA fy+$  nwr \n",
    "hy lmys AlHdydy m$ h+tjyb mSr w+hy Dlm+p w+twlwl zy mA kAn+t b+tEml >yAm mrsy ؟!! \n",
    ">kbr myz+p fy tjrb+p Al+Hb Al+fA$l+p <n+hA b+tErf+k >xTA'+k El$An mA tqE+$ fy+hA tAny \n",
    "fkr+t qbl kdh lyh Al+dhb gAly ؟ El$An mwjwd qlyl ، kAn mmkn Al+Hdyd ybqY mEdn vmyn w+Al+dhb ytEml mn+h msAmyr . Al+>qly+p m$ dAym+A wH$+p . \n",
    ">nA bd>+t >twgw$ ElY fkr+p ؛) kn+ty kwys+p <yh Ally HSl !! AEtrf+y \n",
    "hhh |h bs l+Al+>sf nwr+k fy Al+Syf m$ h+y$gl mrwH+p w+lA tkyyf w+lA tlAj+p ... AstEd+y l+Syf sAxn \n",
    "Ally b+yqwl m$ h+yntxb Hmdyn El$An m$ h+ynjH .. Tyb w+>nt lyh EAy$ w+>nt EArf <n+k h+tmwt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ليه لما تحب حد من قلبك يطلع واطي ليه لما تلعب على واحد يطلع بيحبك ليه اللي هيموت عليك إنت مش طايقه واللي هتموت عليه مش طايقك عجبت لك يا زمن الحمد لالله يا جدعان الفرسان اللي اتمسكوا عند ستاد القاهرة خدوا إخلاء سبيل ربنا كبير .. بقى لنا 7 سنين ظلم وقهر ده يرضي مين ؟؟؟؟ الحمد لالله الواحد لما بينام كتير ، بيحلم بأحلام - هي في الأغلب هلاوس أو حاجات تانية ، بس المهم مش أحلام يعني - ما لهمش أي علاقة ببعض ، متتالية ، وغير منطقية . الدنيا دي عبارة عن امتحان وإحنا فيه يوم ما الامتحان ده بيخلص حياة الإنسان كمان بتخلص ساعتها بقى بيروح يجيب نتيجته .. كنتُ خايف السيسي يطلع ذكي وما يترشحش ,, الحمد لالله الحمار هيلبس :ض ما بقيتْش مشكلة إنهم يضايقواك ولا حتى يزعلواك عادي أصلا ، المشكلة إنك كنتَ فاكرهم حاجة تانية غير كده دنيا آه والله إحساس حلو لما تلاقي حد شبهك في حاجتات كتيرة , ويهتم بنفس الحاجتات اللي بتحبها . فاكره توأم توأم :-ض ( 2 ) تيجي نتكلم ونقول كام نصيحة على كام كلمة حلوة على حبة أي كلام علشان كام ريتويت دايما الواحد بيقصر في حق ناس تستاهل ويسأل على ناس ما تستاهلش :-( يبقى ما تناميش وخليكي قاعدة واسهري برضه لحد ما تفصلي خالص بعد كده نامي بالليل إنت معصوم من الغلط ؟ ! لا ؟ ! طيب ليه بقى بتحسسني لما بأغلط إن دي نهاية العالم يعني ! إنتو مش متخيلين إن بكرة الكلية إزاي ... أنا بأمشي أستخبى من الناس اللي ما بأحبهاش ودول كتير دي حقيقة لالأسف الواحد بقى بيقول ألفاظ ما لهاش أي علاقة بتربيته أبويا لو عرف هيدبحني شقى عمره منهم لالله الباردين أوقات بأشوف حاجتات غريبة بأخاف أقول إنها غريبة أحسن الناس تقول علييا غريب وده بقى الغريب في الموضوع !! أنا لما حد يسألني برجك إيه بأتكسف أقول له العذراء بصراحة أحا أصلا مين اللي سمى الأبراج دي أنا غلطانة إني سمعت كلام ماما نجوى لما قالت سامح يا سامح سامح خليك مسامح سامح كان لازم يأخدوا بالجزمة إحنا جيل اتربى غلط إنت مش شور لما تشرب سجاير علشان توري البنات إنك راجل الموضوع يا بني مش شخصي , أنا ما بأثقش في منبه الموبايل بتاعي .. فلك أن تتخيل بقى غالبا حالة من الاكتئاب الشديد هي بتكون رد سؤال .. هو أنا لو جرى لي حاجة هأفرق مع مين ؟ المشاكل دايما بتبدأ لما تقرب من أي حد زيادة عن اللزوم , العلاقتات السطحية قادرة تحمينا من حاجتات كتير . كله يحضر هدية عيد الأم . بوسوا إيد أمهاتكم واشكروا ربنا إنهم عايشين وسطنا عارفين إنتو الشخصية اللي بتيجي في وسط عياطك وتقول لك إنت شكلك كيوت قوي وأنت بتعيط ويشد في خدودك العالم دي هتموت محروقة :ض إحنا مش عايزين نموت نفسنا .. إحنا فيه حاجات معينة في حياتنا نفسنا نموتها أنا محتاجة أجيب شخص لبناني يتكلم معايا في أي كلام علشان لهجتهم بتبسطني ما حدش محتاج من حد حاجة الحالة 100 فل ومرضية الفكرة بس في التقدير وده مش بفلوس ده كبيره سؤال بصافي نية طيب العيب في مين ؟ في الفيزيا ؟ لا علشان فيه ناس بتفهمها . طيب في المستر ؟ لا علشان فيه ناس بتفهمه . يبقى العيب فيا أنا وحسبي الله ونعم الوكيل ! أنا عارفة إنك هتستغربي التويتة دي .... بس أنا فعلا محتاجة مساعدة من دكتور أمراض نفسية ومش عارفة اسم دكتور كويس لا لو سمحت :ض ,, أنا علشان ما بأعرفش أكدب بأكح :ض ,, فيه ناس تانية بتكدب وما بيرمش لهاش رمش :ض قشطة والله هي مشاركة بس علشان موللي فرحانة إنما إحنا أهلاوية حتى النخاع وهي دي الروح الرياضية يوم فرحك إنت بتختار مين يجي لك , بس يوم موتك ناس معينة هي اللي هتختار تيجي ! كان بيطلع مونولوجست على خشبة المسرح بين فصول الرواية يسلي الجمهور . المرة دي طلع مبتذل . ربنا خده الحمد لالله نرجع لالجد بقى يا رب أنا مش عايز أجيب مجموع علشاني ، أنا عايز أجيب مجموع علشان أبويا وأمي وعلشان فلوس الدروس دي مش مال حرام يعني ! ثانوية عامة أنا أخويا سريره بيبقى فيه كل حاجة بيبقى نايم وحواليه أكل وفاكهة وقزايز مياه وشرابات وموبايله واللاب توب والريموت أي حاجة ضايعة في البيت بنلاقيها هيعجب بيكي علشان شكلك وهيعجب بيكي علشان شخصيتك بس في الآخر هيتقدم لك علشان أخلاقك بس وأي حد هيحكم مصر هأدعي له ربنا يوفقه لالصح علشان عايزة بلدي تبقي أحسن وما دام الناس مبسوطة وعايزاه ربنا يوفقه ويوفقنا معاه لو حبيت حد ما تأخدش رأي الناس فيه علشان إنت اللي اخترته مش الناس الحالة الزفت اللي الواحد بيبقى فيها بقت ملازماه على طول ! ربنا المعين أنا وصلت لمرحلة إني ممكن أنام وأنا واقفة زي الحصنة عادي :ض مشكلة كتير من الناس إنها افتكرت الثورة حاجة سعيدة ولطيفة لا دي من أقسى التجارب اللي بتمر ببلد شعور عالمي لا يماثله شعور لما تتفاجئ إن النهاردة الخميس مش الأربع :) بتحصل كتير هتفضلي كده كتير ؟! وﻻ هيرجع حاجة وﻻ هيقدم حاجة . اتخلصي من السلبيات دي واستمتعي بحياتك :) ودي أقل حاجة تقدري تقدميها لاللي بيحبوكي ما تنسواش البرسيم اللي كان وراه في الخلفية دي ليها معنى كبير وصول أول مرشح رئاسي لمقر العليا .. ويؤكد : برنامجي في دماغي أ ابتدينا الهبل والعك . دماغك مين يا عم ؟ كبر دماغك شوية طيب النور قطع النهاردة أكتر ما جه ده ولسة التكييفات ما اشتغلتش وبكرة تشوفوا مصر :( ما فيش نور هي لميس الحديدي مش هتجيب مصر وهي ضلمة وتولول زي ما كانت بتعمل أيام مرسي ؟!! أكبر ميزة في تجربة الحب الفاشلة إنها بتعرفك أخطاءك علشان ما تقعش فيها تاني فكرت قبل كده ليه الدهب غالي ؟ علشان موجود قليل ، كان ممكن الحديد يبقى معدن ثمين والدهب يتعمل منه مسامير . الأقلية مش دايما وحشة . أنا بدأت أتوغوش على فكرة ؛) كنتي كويسة إيه اللي حصل !! اعترفي ههه آه بس لالأسف نورك في الصيف مش هيشغل مروحة ولا تكييف ولا تلاجة ... استعدي لصيف ساخن اللي بيقول مش هينتخب حمدين علشان مش هينجح .. طيب وأنت ليه عايش وأنت عارف إنك هتموت\n"
     ]
    }
   ],
   "source": [
    "print from_buck_to_utf8(arz_test.replace('+', ''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
