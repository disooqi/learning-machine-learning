Detailed implemention of of Neural Network for educational purboses perpouses

Backpropagation is implemented in boring detail such that derivative steps is taken carefully and without any implicit or hidden 
details

## Softmax
* https://stats.stackexchange.com/questions/235528/backpropagation-with-softmax-cross-entropy
* https://algorithmsdatascience.quora.com/BackPropagation-a-collection-of-notes-tutorials-demo-and-codes
* https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/
* https://stackoverflow.com/questions/33541930/how-to-implement-the-softmax-derivative-independently-from-any-loss-function
* https://eli.thegreenplace.net/2016/the-chain-rule-of-calculus/


## CNN
* http://deeplearning.net/tutorial/lenet.html
* https://www.kdnuggets.com/2018/04/derivation-convolutional-neural-network-fully-connected-step-by-step.html#.WtijFNOWxlI.facebook


## LSTM
* https://arxiv.org/abs/1503.04069
* http://colah.github.io/posts/2015-08-Understanding-LSTMs/
* http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/
* https://deeplearning4j.org/lstm.html
* https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html
* https://www.quora.com/What-is-the-clearest-presentation-of-backpropagation-through-time-for-LSTMs
* https://stackoverflow.com/questions/41555576/lstm-rnn-backpropagation

## RNN
* https://arxiv.org/pdf/1610.02583.pdf
* http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/
* http://peterroelants.github.io/posts/rnn_implementation_part01/
* http://willwolf.io/2016/10/18/recurrent-neural-network-gradients-and-lessons-learned-therein/
* https://www.analyticsvidhya.com/blog/2017/12/introduction-to-recurrent-neural-networks/
* http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/
* https://machinelearningmastery.com/gentle-introduction-backpropagation-time/



